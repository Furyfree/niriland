#!/usr/bin/env bash

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
source "$SCRIPT_DIR/../lib/common"

SYSTEMD_SRC_DIR="$REPO_ROOT/configs/system/etc/systemd/system"
OPENWEBUI_SERVICE_DST="/etc/systemd/system/openwebui.service"
OPENWEBUI_SERVICE_CPU="$SYSTEMD_SRC_DIR/openwebui.service"
OPENWEBUI_SERVICE_NVIDIA="$SYSTEMD_SRC_DIR/openwebui-nvidia.service"
OPENWEBUI_PORT="3210"
MODEL_NVIDIA="${NIRILAND_OLLAMA_MODEL_NVIDIA:-qwen2.5-coder:14b}"
MODEL_CPU="${NIRILAND_OLLAMA_MODEL_CPU:-qwen2.5-coder:3b}"

has_nvidia_hardware() {
  if command -v lspci >/dev/null 2>&1 && lspci | grep -qi 'nvidia'; then
    return 0
  fi

  if command -v nvidia-smi >/dev/null 2>&1; then
    return 0
  fi

  return 1
}

is_nvidia_runtime_ready() {
  if ! command -v nvidia-smi >/dev/null 2>&1; then
    return 1
  fi

  # CUDA workloads require the driver to be loaded and nvidia-smi to work.
  nvidia-smi >/dev/null 2>&1
}

install_opencode_if_missing() {
  if command -v opencode >/dev/null 2>&1; then
    log "Opencode already installed, skipping."
    return 0
  fi

  require_cmd curl
  log "Installing Opencode..."
  if curl -fsSL https://opencode.ai/install | bash; then
    log_success "Opencode installed."
  else
    warn "Opencode installation failed, continuing."
  fi
}

install_codex_if_missing() {
  if command -v codex >/dev/null 2>&1 || [[ -x "$HOME/.local/bin/codex" ]]; then
    log "Codex already installed, skipping."
    return 0
  fi

  install_package npm
  log "Installing Codex..."
  if npm i -g @openai/codex --prefix "$HOME/.local"; then
    log_success "Codex installed."
  else
    warn "Codex installation failed, continuing."
  fi
}

pull_model_if_missing() {
  local model="$1"
  if ollama list 2>/dev/null | awk 'NR > 1 { print $1 }' | grep -Fxq "$model"; then
    log "Model $model already present, skipping."
    return 0
  fi

  log "Pulling model $model..."
  ollama pull "$model"
}

setup_openwebui_service() {
  local service_src="$1"
  local image="$2"

  [[ -f "$service_src" ]] || die "OpenWebUI service template not found: $service_src"

  if run_sudo docker image inspect "$image" >/dev/null 2>&1; then
    log "OpenWebUI image already present: $image"
  else
    log "Pulling OpenWebUI image: $image"
    run_sudo docker pull "$image"
  fi

  if run_sudo docker ps -a --format '{{.Names}}' | grep -Fxq "open-webui"; then
    log "Removing existing open-webui container"
    run_sudo docker rm -f open-webui >/dev/null
  fi

  copy_file "$service_src" "$OPENWEBUI_SERVICE_DST"
  run_sudo systemctl daemon-reload
  run_sudo systemctl enable --now openwebui
  run_sudo systemctl restart openwebui
}

log "Setting up local AI tools"
install_opencode_if_missing
install_codex_if_missing

log "Setting up Ollama"
install_package ollama
run_sudo systemctl enable --now ollama
install_package docker
run_sudo systemctl enable --now docker.service

if is_nvidia_runtime_ready; then
  log "NVIDIA runtime detected and ready"
  install_package nvidia-container-toolkit
  run_sudo nvidia-ctk runtime configure --runtime=docker
  run_sudo systemctl restart docker

  pull_model_if_missing "$MODEL_NVIDIA"
  setup_openwebui_service "$OPENWEBUI_SERVICE_NVIDIA" "ghcr.io/open-webui/open-webui:cuda"
else
  if has_nvidia_hardware; then
    warn "NVIDIA hardware detected, but runtime is not ready. Falling back to CPU image."
    warn "If you expect CUDA, verify drivers/modules and retry after reboot."
  else
    log "Non-NVIDIA system detected"
  fi

  pull_model_if_missing "$MODEL_CPU"
  setup_openwebui_service "$OPENWEBUI_SERVICE_CPU" "ghcr.io/open-webui/open-webui:main"
fi

log_success "AI setup complete."
log_success "OpenWebUI URL: http://localhost:$OPENWEBUI_PORT"
